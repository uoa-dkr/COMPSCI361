{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Linear Regression.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Example of Linear Regression from Scratch.\n",
        "\n",
        ". Two functions Predict and Calculating Coefficient using SGD."
      ],
      "metadata": {
        "id": "xY-ZetJEwWjW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CpfeTbP-i8js",
        "outputId": "13147584-575e-4118-b087-5cce639f37ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">epoch=0, lrate=0.001, error=273.569\n",
            ">epoch=1, lrate=0.001, error=242.800\n",
            ">epoch=2, lrate=0.001, error=215.494\n",
            ">epoch=3, lrate=0.001, error=191.262\n",
            ">epoch=4, lrate=0.001, error=169.756\n",
            ">epoch=5, lrate=0.001, error=150.671\n",
            ">epoch=6, lrate=0.001, error=133.733\n",
            ">epoch=7, lrate=0.001, error=118.702\n",
            ">epoch=8, lrate=0.001, error=105.363\n",
            ">epoch=9, lrate=0.001, error=93.524\n",
            ">epoch=10, lrate=0.001, error=83.018\n",
            ">epoch=11, lrate=0.001, error=73.694\n",
            ">epoch=12, lrate=0.001, error=65.420\n",
            ">epoch=13, lrate=0.001, error=58.076\n",
            ">epoch=14, lrate=0.001, error=51.559\n",
            ">epoch=15, lrate=0.001, error=45.775\n",
            ">epoch=16, lrate=0.001, error=40.642\n",
            ">epoch=17, lrate=0.001, error=36.087\n",
            ">epoch=18, lrate=0.001, error=32.044\n",
            ">epoch=19, lrate=0.001, error=28.456\n",
            ">epoch=20, lrate=0.001, error=25.272\n",
            ">epoch=21, lrate=0.001, error=22.446\n",
            ">epoch=22, lrate=0.001, error=19.938\n",
            ">epoch=23, lrate=0.001, error=17.712\n",
            ">epoch=24, lrate=0.001, error=15.737\n",
            ">epoch=25, lrate=0.001, error=13.984\n",
            ">epoch=26, lrate=0.001, error=12.428\n",
            ">epoch=27, lrate=0.001, error=11.047\n",
            ">epoch=28, lrate=0.001, error=9.821\n",
            ">epoch=29, lrate=0.001, error=8.733\n",
            ">epoch=30, lrate=0.001, error=7.768\n",
            ">epoch=31, lrate=0.001, error=6.911\n",
            ">epoch=32, lrate=0.001, error=6.150\n",
            ">epoch=33, lrate=0.001, error=5.475\n",
            ">epoch=34, lrate=0.001, error=4.876\n",
            ">epoch=35, lrate=0.001, error=4.344\n",
            ">epoch=36, lrate=0.001, error=3.873\n",
            ">epoch=37, lrate=0.001, error=3.454\n",
            ">epoch=38, lrate=0.001, error=3.082\n",
            ">epoch=39, lrate=0.001, error=2.752\n",
            ">epoch=40, lrate=0.001, error=2.459\n",
            ">epoch=41, lrate=0.001, error=2.199\n",
            ">epoch=42, lrate=0.001, error=1.968\n",
            ">epoch=43, lrate=0.001, error=1.763\n",
            ">epoch=44, lrate=0.001, error=1.581\n",
            ">epoch=45, lrate=0.001, error=1.419\n",
            ">epoch=46, lrate=0.001, error=1.276\n",
            ">epoch=47, lrate=0.001, error=1.149\n",
            ">epoch=48, lrate=0.001, error=1.036\n",
            ">epoch=49, lrate=0.001, error=0.935\n",
            "[0.5753110545951534, 2.0018366617051933]\n"
          ]
        }
      ],
      "source": [
        "def predict(row, coefficients):\n",
        "\tyhat = coefficients[0]\n",
        "\tfor i in range(len(row)-1):\n",
        "\t\tyhat += coefficients[i + 1] * row[i]\n",
        "\treturn yhat\n",
        " \n",
        "# Estimate linear regression coefficients using stochastic gradient descent\n",
        "def coefficients_sgd(train, l_rate, n_epoch):\n",
        "\tcoef = [0.0 for i in range(len(train[0]))]\n",
        "\tfor epoch in range(n_epoch):\n",
        "\t\tsum_error = 0\n",
        "\t\tfor row in train:\n",
        "\t\t\tyhat = predict(row, coef)\n",
        "\t\t\terror = yhat - row[-1]\n",
        "\t\t\tsum_error += error**2\n",
        "\t\t\tcoef[0] = coef[0] - l_rate * error\n",
        "\t\t\tfor i in range(len(row)-1):\n",
        "\t\t\t\tcoef[i + 1] = coef[i + 1] - l_rate * error * row[i]\n",
        "\t\tprint('>epoch=%d, lrate=%.3f, error=%.3f' % (epoch, l_rate, sum_error))\n",
        "\treturn coef\n",
        " \n",
        "# Calculate coefficients\n",
        "dataset = [[1, 3], [2, 5], [3, 7], [4, 9], [5, 11]]\n",
        "l_rate = 0.001\n",
        "n_epoch = 50\n",
        "coef = coefficients_sgd(dataset, l_rate, n_epoch)\n",
        "print(coef)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example on Wine Quality Data. \n",
        "\n"
      ],
      "metadata": {
        "id": "fapQpN-yv7Un"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Linear Regression With Stochastic Gradient Descent for Wine Quality\n",
        "from random import seed\n",
        "from random import randrange\n",
        "from csv import reader\n",
        "from math import sqrt\n",
        " \n",
        "# Load a CSV file\n",
        "def load_csv(filename):\n",
        "\tdataset = list()\n",
        "\twith open(filename, 'r') as file:\n",
        "\t\tcsv_reader = reader(file)\n",
        "\t\tfor row in csv_reader:\n",
        "\t\t\tif not row:\n",
        "\t\t\t\tcontinue\n",
        "\t\t\tdataset.append(row)\n",
        "\treturn dataset\n",
        " \n",
        "# Convert string column to float\n",
        "def str_column_to_float(dataset, column):\n",
        "\tfor row in dataset:\n",
        "\t\trow[column] = float(row[column].strip())\n",
        " \n",
        "# Find the min and max values for each column\n",
        "def dataset_minmax(dataset):\n",
        "\tminmax = list()\n",
        "\tfor i in range(len(dataset[0])):\n",
        "\t\tcol_values = [row[i] for row in dataset]\n",
        "\t\tvalue_min = min(col_values)\n",
        "\t\tvalue_max = max(col_values)\n",
        "\t\tminmax.append([value_min, value_max])\n",
        "\treturn minmax\n",
        " \n",
        "# Rescale dataset columns to the range 0-1\n",
        "def normalize_dataset(dataset, minmax):\n",
        "\tfor row in dataset:\n",
        "\t\tfor i in range(len(row)):\n",
        "\t\t\trow[i] = (row[i] - minmax[i][0]) / (minmax[i][1] - minmax[i][0])\n",
        " \n",
        "# Split a dataset into k folds\n",
        "def cross_validation_split(dataset, n_folds):\n",
        "\tdataset_split = list()\n",
        "\tdataset_copy = list(dataset)\n",
        "\tfold_size = int(len(dataset) / n_folds)\n",
        "\tfor i in range(n_folds):\n",
        "\t\tfold = list()\n",
        "\t\twhile len(fold) < fold_size:\n",
        "\t\t\tindex = randrange(len(dataset_copy))\n",
        "\t\t\tfold.append(dataset_copy.pop(index))\n",
        "\t\tdataset_split.append(fold)\n",
        "\treturn dataset_split\n",
        " \n",
        "# Calculate root mean squared error\n",
        "def rmse_metric(actual, predicted):\n",
        "\tsum_error = 0.0\n",
        "\tfor i in range(len(actual)):\n",
        "\t\tprediction_error = predicted[i] - actual[i]\n",
        "\t\tsum_error += (prediction_error ** 2)\n",
        "\tmean_error = sum_error / float(len(actual))\n",
        "\treturn sqrt(mean_error)\n",
        " \n",
        "# Evaluate an algorithm using a cross validation split\n",
        "def evaluate_algorithm(dataset, algorithm, n_folds, *args):\n",
        "\tfolds = cross_validation_split(dataset, n_folds)\n",
        "\tscores = list()\n",
        "\tfor fold in folds:\n",
        "\t\ttrain_set = list(folds)\n",
        "\t\ttrain_set.remove(fold)\n",
        "\t\ttrain_set = sum(train_set, [])\n",
        "\t\ttest_set = list()\n",
        "\t\tfor row in fold:\n",
        "\t\t\trow_copy = list(row)\n",
        "\t\t\ttest_set.append(row_copy)\n",
        "\t\t\trow_copy[-1] = None\n",
        "\t\tpredicted = algorithm(train_set, test_set, *args)\n",
        "\t\tactual = [row[-1] for row in fold]\n",
        "\t\trmse = rmse_metric(actual, predicted)\n",
        "\t\tscores.append(rmse)\n",
        "\treturn scores\n",
        " \n",
        "# Make a prediction with coefficients\n",
        "def predict(row, coefficients):\n",
        "\tyhat = coefficients[0]\n",
        "\tfor i in range(len(row)-1):\n",
        "\t\tyhat += coefficients[i + 1] * row[i]\n",
        "\treturn yhat\n",
        " \n",
        "# Estimate linear regression coefficients using stochastic gradient descent\n",
        "def coefficients_sgd(train, l_rate, n_epoch):\n",
        "\tcoef = [0.0 for i in range(len(train[0]))]\n",
        "\tfor epoch in range(n_epoch):\n",
        "\t\tfor row in train:\n",
        "\t\t\tyhat = predict(row, coef)\n",
        "\t\t\terror = yhat - row[-1]\n",
        "\t\t\tcoef[0] = coef[0] - l_rate * error\n",
        "\t\t\tfor i in range(len(row)-1):\n",
        "\t\t\t\tcoef[i + 1] = coef[i + 1] - l_rate * error * row[i]\n",
        "\t\t\t# print(l_rate, n_epoch, error)\n",
        "\treturn coef\n",
        " \n",
        "# Linear Regression Algorithm With Stochastic Gradient Descent\n",
        "def linear_regression_sgd(train, test, l_rate, n_epoch):\n",
        "\tpredictions = list()\n",
        "\tcoef = coefficients_sgd(train, l_rate, n_epoch)\n",
        "\tfor row in test:\n",
        "\t\tyhat = predict(row, coef)\n",
        "\t\tpredictions.append(yhat)\n",
        "\treturn(predictions)\n",
        " \n",
        "# Linear Regression on wine quality dataset\n",
        "seed(1)\n",
        "# load and prepare data\n",
        "filename = 'winequality-white.csv'\n",
        "dataset = load_csv(filename)\n",
        "for i in range(len(dataset[0])):\n",
        "\tstr_column_to_float(dataset, i)\n",
        "# normalize\n",
        "minmax = dataset_minmax(dataset)\n",
        "normalize_dataset(dataset, minmax)\n",
        "# evaluate algorithm\n",
        "n_folds = 10\n",
        "l_rate = 0.01\n",
        "n_epoch = 50\n",
        "scores = evaluate_algorithm(dataset, linear_regression_sgd, n_folds, l_rate, n_epoch)\n",
        "print('Scores: %s' % scores)\n",
        "print('Mean RMSE: %.3f' % (sum(scores)/float(len(scores))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMUsw5cPkgA9",
        "outputId": "207df953-b9a0-4c9c-e777-246103bcbb31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scores: [0.12453287777501727, 0.12020384693685336, 0.12737875736842358, 0.13239752740416907, 0.12456380149227336, 0.1271030436562122, 0.132081664696156, 0.12451827916228461, 0.12817467520611905, 0.12082332031663615]\n",
            "Mean RMSE: 0.126\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question:\n",
        "\n",
        "What happens if you change the n_folds, l_rate, n_epochs?"
      ],
      "metadata": {
        "id": "rTFWiZQYwFo0"
      }
    }
  ]
}